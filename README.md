# Compression
Tasks for compression course

## lab 1
The program will calculate the frequency of symbols occurrence and the frequency of symbols occurring after a given one, and has functions that will calculate entropy and conditional entropy for calculated frequencies treated as random variables.

## lab 2
Implementation of Huffman encoding and decoding

## lab 3
The program can encode and decode a given file using the LZW algorithm. Series
dictionary index values ​​are encoded with universal encoding. The input alphabet is 8-bit codes. By default, the program uses Elias ω encoding, but has the option of using other Elias encodings as well
Fibonacci coding. In addition, when coding, it provides the length of the encoded file, the length of the obtained code, compression ratio, entropy of the encoded text and entropy of the obtained code.

## lab 4
The program for uncompressed images saved in the TGA1 format will count the coding results using the difference between the JPEG-LS predictors and will provide entropy for the code of the entire image as well as individual color components.

## lab 5
The program for the uncompressed image saved in the TGA format will count the image obtained as a result of uniform quantization of individual color components and write the average square error for the entire image and individual color components as well as the signal-to-noise ratio.

## lab 6
The program encodes and decodes a given image in TGA format using differential coding with a uniform quantizer and takes as a parameter the number of bits of the quantizer.

## lab 7
Extended Hamming code (8, 4)
